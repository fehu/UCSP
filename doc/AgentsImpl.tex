\subsection{Agents Implementation}

Agents are implemented using \emph{Software Transactional Memory} (STM)
\cite{STMCode07} --- a promising concurrency paradigm.
They are executed in two computational threads:
one for message handling and another for proactive action.

\medskip

\noindent
Agent's behavior is flexible and may be changed during agent's lifetime.
As it was mentioned before, it is determined by \emph{message handling} and
\emph{action} functions.
Any complex behaviour would require the agent to have some \emph{mutable}
internal \emph{states}, where it could store some information,
thus remembering it throughout behaviour executions.
The only restriction is that states interface must be fixed for type safety
(only the interface, not the underlying data).


Each agent also has two system states: the \emph{run state} and special \emph{shared
  state}, called \emph{status}. The run state controls agent's execution
(and termination), while the status is monitored by the respective controller.
Agents have three \emph{run states}: ``Paused'', ``Running'' and ``Terminate''.
The first two states should control pro-action;
setting the last one should cause all agent's processes to stop.
The \emph{status}es are further described in section \ref{agentControllers}.

\medskip

To ensure agents isolation, the direct interactions are restricted;
an agent only exposes its communication interface through \emph{agent reference}.

Using this interface, one can simply \emph{send} a message to an agent,
or one can \emph{ask} for some \emph{expected response}, corresponding to the message sent.
Agents have separate handler functions for theese two cases.

% \medskip

% All behavior functions
% accept two arguments:
% \begin{enumerate}
% \item the agent's \emph{inner interface}, that provides
%   control over agent's own behavior and lifetime;
% \item agent's \emph{internal state}.
% \end{enumerate}

% \subsubsection{Negotiation}
%
%
% A negotiation has a \emph{classes pool}, distributed between the agents.
% A class $\left< d, g, p, r, \bar d, t, t \right>$ is known to agents,
% representing $g$, $p$ and $r$.
%
% Negotiations are organized by special kind of agents --- \emph{controllers}.
%
% \red{TODO}






\subsection{Controllers}
\red{rename: ``Controller'' => ``Observer''}

The controllers create new negotiating agents, and monitor their \emph{status}es
over their lifetimes. Controllers also provide communication references for the
agents they control. In order to facilitate references sharing, the controllers
are restricted to a single \emph{role} for it's agents.

Controllers have hierarchical structure, starting with the \emph{root
  controller}. The orders received by \emph{root} are propagated to
the underlying controllers.

\medskip

As mentioned before, negotiating agents have a special state,
called \emph{status}, that is monitored by the controllers. Apart
from receiving agents' errors, the \emph{status}es are used to
extract the \emph{distributed solution} from the agents.
This is done using ``Waiting'' and ``Locked'' statuses.

The agents set ``Waiting'' status when a suitable solution is found,
and the corresponding controller waits for all of its subjugated
agents to set it. When it is done, the controller sends ``Lock''
command to the agents and notifies the \emph{parent controller}.
When the \emph{root controller} receives ``Lock'' notifications from
all the controllers, it sends ``Collect'' order. On that order, the controllers
extract the solution parts (guarded in the statuses) and propagate them up to
the root.
