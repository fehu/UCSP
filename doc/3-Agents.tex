\documentclass[ThesisDoc]{subfiles}

\providecommand{\rootdir}{.}
\input{MathDefs}

\begin{document}

\chapter{Agents}
% \green{Explicar qué son los agentes}
% \medskip


% \green{Poner algunas definiciones}
% \medskip

An \emph{agent} has no generally accepted definition, but the idea is traced back
to the antique times. The survey of \cite[sec.~2.2]{PNoriega} gives several
definitions, proposed by different authors, ranging from philosophy to AI.

The notion of agent appears in Aristotle's works:
 ``entity that acts with a purpose, within a social context''.
The prætorian roman law defined an agent as
``a person who acts on behalf of a principal for
a specific purpose and under limited delegation of authority and responsibility''.

The earliest use of the term agent in AI was
``a program that is capable of executing an action vicariously''.
Later it was formulated as \emph{a computer system, which}
\begin{enumerate}
  \item has a degree of autonomy in determining its behavior,
  \item interacts with humans and or other agents,
  \item perceives the environment and reacts to it, and
  \item exhibits a goal directed behavior.
\end{enumerate}

\bigskip

There are three general approaches to defining/describing agents:
\begin{enumerate}
  \item \emph{Agent Theories} discuss what an agent \emph{is} and formalize
    it in mathematical form.
  \item \emph{Agent architectures} deal with the \emph{implementations}
    of the Agent Theories, physical (hardware) and/or logical (software).
  \item \emph{Agent languages} are software systems, that allow communication
    between the agents (including human/living ones).
\end{enumerate}


Many authors have thought of agents as \emph{logical theories}, that perceive
the environment as formulas, that are processed within or against those theories.
An agent is usually required to be capable of proactive behavior, not
just responses to environment changes. Some authors impose stronger demands upon
the agents, such as mobility, truthfulness, benevolence, rationality.

The most notable agent theory is the \emph{Beliefs-Desires-Intentions} (BDI) one,
that deduces agent's intentions (and the following sequence of actions)
from its desires (goals) and an uncertain image of the environment (beliefs).


Some works (for example \cite{UAB-Thesis} and \cite{PNoriega}) propose
layered architectures, where each layer (for example: \emph{Beliefs} or \emph{Intentions})
has its own logic. The ``logics'' are then united using \emph{bridge rules}.

% \todo\red{: add another source.}


\medskip

\noindent
One could summarize that an agent is primarily a computational entity (software),
but it might have a (robotic) ``body''.
The BDI theory, for example, allows to abstract existence of a ``body'',
by seeing it as an actuator withing the environment, that \emph{tries} to
implement agent's current \emph{intention}.
The actual results of an interaction should not be taken as predefined, but rather
as probabilistic, observable through the \emph{beliefs}. As an example, one can
see a human being as an agent of its \emph{ego}, that determines the \emph{desires}.
As we all well know, not all the \emph{intention} always come out as expected.
It depends, of course, on how general one understands intention, but whether
it's an intention to go to Mars or to lift a pen, there is always a degree of
uncertainty. Our brain, as an actuator, transforms motion intentions into
neuronal signals, even if there destination was severed or the neural connections
were damaged; there is no way of knowing the results of intention implementation
except from new information.

\bigskip

\noindent
An agent should be capable of:
\begin{enumerate}
  \item \emph{autonomous} and \emph{goal directed} behavior,
  \item perception of and interaction with the environment,
  \item communication with other agents (including humans).
\end{enumerate}

% \todo\red{: this is basically a repetition}

\section{Solving CSPs with Multiagent Systems}
\label{sec:CSP-Agents}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \green{Explicar cómo se pueden resolver los CSP con agentes}
% \medskip

Multiagent Systems (MAS) have been successfully used to solve
different \emph{constraints satisfaction problems} \cite{MAS, MAS-Survey}.
Each problem variable is given to an agent, that would try to set its value,
avoiding contradictions with the values of its ``neighbouring'' agents.
There are different methods and techniques for implementing agents behavior.

One of the simplest methods consists in taking all possible variable domain values
and eliminating the values, that are in contradiction with the neighbors.
The process results in a solution if when all the agents have exactly one
possible value; or it fails if any of the agents runs out of the possible
values to propose. A natural question arises: in what order should the agents
prune their domains?
It can be resolved by assigning a distinct comparable priority value to each agents.
In such case a value should be excluded only if neighbor's priority exceeds own priority.
Combined with \emph{backtracking} technique, it guarantees finding a solution,
if it exists.

\noindent
An agent $a_i$
\begin{enumerate}
  \item controls variable $v_i$ with a finite $\domain~v_i =
        \{{\dot v}^i_j\}_{j=1}^{N_i}$, can set it's value ${\dot V}_i$,
  \item has sets of possible ${\tilde V}_i$ and excluded ${\tilde V}_i^-$ values,
  \item has priority $p$.
\end{enumerate}

\noindent
In the beginning each agent assigns
\begin{align*}
  &{\tilde V}_i   &&\leftarrow \domain~v_i       && \textit{(any domain value is possible)} & \\
  &{\tilde V}_i^- &&\leftarrow \{\}              && \textit{(no excluded values at start)}  &\\
  &{\dot V}_i     &&\leftarrow \pop~{\tilde V}_i && \textit{(pop first possible value and assign it to the variable)} &\\
\end{align*}

Every time current value ${\dot V}_i$ is assigned, an agent must notify its
neighbors about it with a \emph{proposal} message, containing the value.
The interactions between agents are heavily based on their priority and are
defined for pairs, where one of the agents always has a higher priority.

Agents communications can be divided in two groups, each depending on the relative
priorities.
\begin{enumerate}
  \item Testing constraints of the \textbf{lower priority} agents by the
    \textbf{higher priority} ones.
    Each agent must notify its neighbors on every value assignment and wait
    for a confirmation from the higher priority ones. If any of them responds
    negatively, the agent must try next \emph{possible} value from ${\tilde V}_i$.
    In case that possible values have ended (${\tilde V}_i = \emptyset$), the agent
    must notify its direct superior (the neighbor with the next highest priority)
    about it, starting the \emph{backtracking}.
  \item Backtracking permits to exit dead-end solution branches, thus allowing
    to check \emph{every possible values combination} with limited resources.

    As written in previous item, the backtracking process starts when an agent
    finds itself without possible values to assign. It has searched all of its
    domain, but no solution to its part of a problem exists. Therefore it is
    necessary that a higher priority agent changes its value. It is better to
    keep the process ordered and the next priority agent is a rational choice
    for a supervisor.

    Upon a notification about solution incoherence, the supervisor
    must try to change its value ${\tilde V}_s$ and add the old one to the
    excluded set ${\tilde V}_i^-$.
    If neither this agent has more possible values to assign, it should propagate
    backtracking request to its own supervisor, and so on. Otherwise, it should
    demand its subordinates to reset their ${\tilde V}_*$ and ${\dot V}_*$ states
    before changing its value. New \emph{possible values} sets are formed, considering
    the excluded values: ${\tilde V}_* = \domain~v_* \setminus {\tilde V}_*^-$.
    Backtracking request by the \emph{top priority} agent means that no solution
    could be found.
\end{enumerate}

The \textbf{stop criteria} is the lack of negotiation activity, that signalizes
that all the values assignations have been confirmed, thus a solution, satisfying
the constraints, was found.

\bigskip
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent
There are various extensions of the method that improve its speed.

One of such techniques is \emph{Weak-commitment Search}\cite{Weak-commitment}.
It can be used when the agents control several variables. It consists in
aggregating variables into negotiation one-by-one, finding \emph{partial solutions}
at each step, until all the variables are aggregated and the final solution
is found. When a (partial) solution cannot be found for a newly aggregated
variable, a process, similar to backtracking, is used to change previous
partial solutions.

A good example of a problem, that is solved much faster this way, is
\emph{n-queen} problem. If one considers the position variable
$\left< x,y \right>$ as two variables, owned by the same agent, the queens
can be positioned first by rows and then by columns, or vice versa. Anyway,
the number of combinations to consider is reduced greatly, thus accelerating
solution search.

There is, for example, a technique, that manipulates agents priorities,
decreasing the priorities of the agents that have fallen back in the backtracking
procedure and rising the priorities of their subordinates. It reduces the
the negotiation time, by shortening the subordinates chains, that are
revised on every backtrack event, of frequently changing agents.

\bigskip

\noindent
In \cite{MAS-Survey} the MAS are classified by two properties of the agents,
that form the system: heterogeneity and communications.
The classification is presented in table \ref{table:MAS-Table}. It denotes
that CSPs are usually solved by \emph{heterogeneous communicating} agents.

\begin{table}
  \centering
  \begin{tabular}{P{0.1\textwidth} P{0.3\textwidth}|P{0.4\textwidth}}
    & \centering Homogeneous & Heterogeneous \\
    \begin{minipage}{0.1\textwidth}
      \rotatebox[origin=tr]{90}{Non-Communicating}
    \end{minipage}
                      & \begin{minipage}{0.3\textwidth}
                        \footnotesize \begin{itemize}[leftmargin=5px, rightmargin=0px]
                          \item Reactive vs. deliberative agents
                          \item Local or global perspective
                          \item Modeling of other agents' states
                          \item How to affect others
                        \end{itemize}\end{minipage}
                      & \begin{minipage}{0.4\textwidth}
                        \footnotesize\begin{itemize}[leftmargin=10px, rightmargin=0px]
                          \item[]
                          \item Benevolence vs. competitiveness
                          \item Fixed vs. learning agents (arms race, credit assignment)
                          \item Modeling of others’ goals, actions, and knowledge
                          \item Resource management (interdependent actions)
                          \item Social conventions
                          \item Roles
                          \item[]
                        \end{itemize}\end{minipage}
                      \\\hline
                      % \\ \rule{0pt}{4ex}\\\hline\\\rule{0pt}{4ex}
    \begin{minipage}{0.1\textwidth}
      \rotatebox[origin=tr]{90}{Communicating}
    \end{minipage}
                      & \begin{minipage}{0.3\textwidth}
                        \footnotesize\begin{itemize}[leftmargin=5px, rightmargin=0px]
                          \item Distributed sensing
                          \item Communication content
                        \end{itemize}\end{minipage}
                      & \begin{minipage}{0.4\textwidth}
                        \footnotesize\begin{itemize}[leftmargin=10px, rightmargin=0px]
                          \item[]
                          \item Understanding each other
                          \item Planning communicative acts
                          \item Benevolence vs. competitiveness
                          \item Negotiation
                          \item Resource management (schedule coordination)
                          \item Commitment/decommitment
                          \item Collaborative localization
                          \item Changing shape and size
                        \end{itemize}\end{minipage}
  \end{tabular}
  \caption{Issues arising in the various scenarios as reflected in the literature
          \cite[Table~2]{MAS-Survey}.}
  \label{table:MAS-Table}
\end{table}


\section{Negotiating Agents}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:NegotiatingAgents}
% \green{ Explicar qué es lo que tú entiendes por agente.}
% \medskip

A \emph{negotiation} is a process of communication between heterogeneous agents with a
goal of finding such a configuration of variables assignations, that all the
agents involved agree upon it. The results and the time of a negotiation depend
on agents \emph{cooperation}. The latter implies that agents must pursue a
\emph{common goal}, rather than be selfish; it can be formulated as
``the good of many outweigh the good of the one''.


\bigskip

\noindent
In this thesis the following definition of a class of agents is used:
a \textbf{negotiating agent} is an isolated proactive computational entity,
capable of sending and receiving messages.
The \emph{isolation} denotes that agents' variables are protected
from outside access; messaging is the only way an agent can be interacted with.
The \emph{pro-activity} implies a capacity of acting asynchronously,
with no ``external'' cause.


\medskip

An agent is defined by it's behaviour --- the combination of its
\emph{proactive} and \emph{reactive} (message handling) functions.

\begin{flalign*}
  &\behaviour = \left< \behaviour_\act, \behaviour_\react \right>\\
  &\behaviour_\act   : \state \mapsto \action \\
  &\behaviour_\react : \state \times \msg \mapsto \action
\end{flalign*}

Therefore two agents with same behaviour functions should be considered two instances
of the same agent. In must be noted, that all the diference in the behaviour of
two instances is produced by the differences in the states
(both agent's internal state and the environment's one).

\medskip

The agents, participating in a negotiation, are considered \emph{heterogeneous}
(to any degree: from complete heterogeneity to homogeneity).
In order to generalize some agents behaviour, \textbf{negotiation roles} are introduced.
A role describes whom or what an agents represents in the negotiation and
defines \emph{behaviour archetype} --- the rules to build
agent's \emph{behaviour functions}, given some \emph{role-specific} knowledge.

The agents must use a common \emph{communication protocol}, to ensure
understanding between agents of the same or different roles.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
